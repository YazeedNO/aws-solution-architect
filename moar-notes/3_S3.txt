S3
Simple Storage Service
S3 is a safe place to store your files.
It is Object based storage.
It provides secure, durable, highly-scalable object storage.
Data is spread across multiple devices and facilities.

Object based storage Vs Block based storage
Object based storage
Flat files -> Videos, Photos, PDF documents, Word documents
Can't install OS or DB
Block based storage (EC2)
OS or a DB is installed

S3 Basics
1.) S3 is object based
2.) Files can be 0 TB to 5 TB
3.) There is unlimited storage
4.) Files are stored in buckets (fancy name for folder)
5.) S3 is universal namespace, that is the name must be unique globally.
6.) When a file is uploaded to S3 you will receive a HTTP 200 code if the upload was successful.
7.) Amazon guarantees 99.99% availability.
8.) Built for 99.99% availability for the S3 platform.
9.) Amazon guarantees 99.999999999% durability for S3 information. (9x11)
10.) Tiered Storage Available
11.) Lifecycle management
12.) Versioning - Cannot be removed, only be disabled
13.) Encryption
14.) Secure your data using Access Control Lists and Bucket Policies

S3 Storage Tiers/ Classes
1.) S3
durable, immediately available, frequently accessed
99.99% availability, 99.999999999% durability, stored redundancy across multiple devices in multiple facilities and is designed to sustain the loss of 2 facilities concurrently.
2.) S3 - IA (Infrequently Accessed)
durable, immediately available, infrequently accessed
For data that is accessed less frequently but requires rapid access when needed. Lower fee than S3, but you are charged a retrieval fee.
3.) Reduces Redundancy Storage
Data that is easily reproducible such as thumbnails
Designed to provide 99.99% durability and 99.99% availability of objects over a given year.
4.) Glacier -
Very cheap, but used for archival only. It takes 3-5 hours to retrieve from Glacier.

Glacier
Extremely low cost service for data archival
0.01$ per GB per month
Optimized for data that is infrequently accessed for which retrieval time is 3 to 5 hours

Data Consistency model for S3
1.) Read after Write consistency for PUTS of new Objects
2.) Eventual consistency for overwrite PUTS and DELETES (can take some time to propagate)
When you upload a file to S3 it can be immediately read and written to.
But when it is updated or deleted it will take some time to replicate.

S3 object
It is simply a key, value store
1.) Key -> name of the object
2.) Value -> data and is made up of sequence of bytes
3.) Version ID -> important for versioning
4.) Metadata -> data about data you are storing
5.) Subresources
----Access Control Lists
----Torrent

S3 Charges
1.) Storage
2.) Request
3.) Storage Management Pricing
4.) Data Transfer Pricing
5.) Transfer Acceleration

S3 Transfer Acceleration
It enables fast, easy and secure transfer of files over long distances between end users and S3 buckets.
Takes advantage of Amazon CloudFront's globally distributes edge location.
As the data arrives the edge location, data is routed to Amazon S3 over an optimized network path.
http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html

S3 Versioning
1.) Stores all versions of an object (including all writes and even if you delete an object)
2.) Great backup tool
3.) Ones enabled cannot be disabled. It can only be suspended.
4.) Integrated with Lifecycle rules
5.) Versioning MFA Delete capability, which uses multifactor authentication, can be used to provide an additional layer of security

S3 Cross Region Replication
1.) Versioning must be enabled on both the source and destination bucket
2.) Regions must be unique
3.) Files in an existing bucket are not replicated automatically. All subsequent updated files will be replicated automatically.
4.) Delete markers are replicated.
5.) Deleting individual versions or delete markers will not be replicated.

S3 Lifecycle Management
1.) Can be used in conjunction with versioning
2.) Can be applied to current versions and previous versions
3.) Actions that can be performed
----Transition to Standard - Infrequent Access Storage Class (128 kbps and 30 days after the creation date)
----Archive to the Glacier Storage Class (30 days after IA, if relevant)
----Permanently delete

CloudFront
Amazon CloudFront can be used to deliver an entire website, including dynamic, static, streaming and interactive content using a global network of edge locations. Request for the content are automatically routed to the nearest edge location, so the content is delivered with the best possible performance.
Amazon CloudFront is optimized to work with other Amazon Web Services like Amazon Simple Storage Service(Amazon S3), Amazon Elastic Compute Cloud(EC2), Amazon Elastic Load Balancing and Amazon Route53. Amazon CloudFront also works seamlessly with any non-AWS origin server, which stores the original, definitive version of the files.
CDN
Content Delivery Network
A CDN is a system of distributed servers(networks) that deliver webpages and other web content to a user based on the geographical location of the user, the origin of the webpage and a content delivery server.
Edge Location
Location where content is cached
This is separate to an AWS Region/AZ
Edge Locations are not just READ only, you can write to them too.(ie. put an object onto them)
Objects are cached for the life of the TTL(Time To Live).
Cached objects can be cleared but this action is chargeable.
Origin
This is the origin of all the files that the CDN will distribute.
This can be an S3 Bucket, EC2 Instance, an Elastic Load Balancer or Route53.
Distribution
Name given to the CDN
It consists of a collection of Edge locations.
2 types of distributions
1.) Web Distribution
Typically used for websites
2.) RTMP
Real-Time Messaging Protocol
Used for media streaming

S3 Security and Encryption
By default all newly created buckets are PRIVATE
Setup access control for the buckets
1.) Bucket Policies
2.) Access Control Lists
S3 buckets can be configured to create access logs which log all requests made to the S3 bucket. This can be done to another bucket.
Encryption
1.) In Transit
SSL/TLS
2.) At Rest
2.1) Server Side Encryption
2.1.1) S3 Managed Keys - SSE-S3
2.1.2) AWS Key Management Service, Managed Keys - SSE-KMS
2.1.3) Server Side Encryption With Customer Provided Keys - SSE-C
2.2) Client Side Encryption

AWS Storage Gateway
It is a service that connects an on-premises software appliance with cloud-based storage to provide seamless and secure integration between an organization's on-premises IT environment and AWS's storage infrastructure. The service enables you to securely store data to the AWS cloud for scalable and cost-effective storage.
AWS Storage Gateways's software appliance is available for download as a virtual machine(VM) image that you install on a host in your datacenter. Storage Gateway supports either VMware ESXi or Microsoft Hyper-V. Once you have installed your gateway and associated it with your AWS account through the activation process, you can use the AWS Management Console to create the storage gateway option that is right for you.
4 types of Storage gateways
1.) File Gateway (NFS) -> Network File System
Files are stored as objects in your S3 buckets, accessed through Network File System(NFS) mount point. Ownership, permissions and timestamp are durably stored in S3 in the user-metadata of the object associated with the file. Once objects are transferred to S3, they can be managed as native S3 objects and bucket policies such as versioning, lifecycle management and cross-region replication apply directly to object stored in your bucket.
2.) Volumes Gateway (iSCSI) -> Internet Small Computer Systems Interface
The volume interface presents your application with disk volumes using the iSCSI block protocol.
Data written to these volumes can be asynchronously backed up as point-in-time snapshot of your volumes and stored in the cloud as Amazon EBS snapshot. (Elastic Block Store)
Snapshots are incremental backups that capture only changed blocks. All snapshot storage is also compressed to minimize your storage charges.
2 types of Volume Gateways
2.1) Stored Volumes
Stored volumes let you store your primary data locally, while asynchronously backing up that data to AWS. Stored volumes provide your on-premises applications with low-latency access to their entire dataset, while providing durable, off-site backups. You can create storage volumes and mount them as iSCSI devices for your on-premises application servers. Data written to your stored volumes is stored on your on-premises storage hardware. This data is asynchronously backup to Amazon S3 in the form of Amazon EBS snapshots. 1GB - 16TB in size for Stored Volumes.
2.2) Cached Volumes
Cached Volumes let you use Amazon S3 as your primary data storage while retaining frequently accessed data locally in your storage gateway. Cached volumes minimize the need to scale your on-premises storage infrastructure, while still providing your application with low-latency access to their frequently accessed data. You can create storage volumes up to 32TB in size and attach to them as iSCSI devices from your on-premises application server. Your gateway stores data that you write to these volumes in Amazon S3 and retain recently read data in your on-premises storage gateway's cache and upload buffer storage. 1 GB - 32TB in size for Cached Volumes.
3.) Tape Gateway (VTL) -> Virtual Tape Library
It offers a durable cost effective solution to archive data in the AWS Cloud. The VTL interface lets you leverage your existing tape-based backup application infrastructure to store data on virtual tape cartridges that you create on your tape gateway. Each tape gateway if preconfigured with a media changer and tape drive, which are available to an existing client backup application as iSCSI devices. You add tape cartridges as you need to archive your data. Supported by NetBackup, Backup Exec, Veam etc.
Exam Tips
1.) File Gateways
For flat files, stored directly on S3
2.) Volume Gateway
2.1) Stored Volumes
Entire Dataset is stored on site and is asynchronously backed up to S3
2.2) Cached Volumes
Entire Dataset is stored on S3 and the most frequently accessed data is cached on site
3.) Gateway Virtual Tape Library (VTL)
Used to backup and uses popular backup applications like NetBackup, Backup Exec, Veam etc

Snowball
Previously
Import/Export Disk
AWS Import/Export Disk accelerates moving large amounts of data into and out of the AWS cloud using portable storage devices for transport. AWS Import/Export Disk transfers your data directly onto and off of storage devices using Amazon's high-speed internal network and bypass the internet.
Now
Types of Snowballs
1.) Snowball
Snowball is a petabyte-scale data transport solution that uses secure appliances to transfer large amounts of data into and out of AWS. Using Snowball addresses common challenges with large-scale data transfer including high network costs, long transfer times and security concerns. Transferring data with Snowball is simple, fast, secure and can be as little as one-fifth the cost of high-speed internet.
80TB snowball in all regions. Snowball uses multiple layers of security designed to protect your data including tamper-resistant enclosures, 256-bit encryption and an industry-standard Trusted Platform Module (TPM) designed to ensure both security and full-chain of custody of your data. Once your data transfer job has been processed and verified, AWS performs a software erasure of Snowball appliance.
2.) Snowball Edge
AWS Snowball Edge is a 100TB data transfer device with on-board storage and compute capabilities. You can use Snowball Edge to move large amounts of data into and out of AWS, as a temporary storage tier for large local datasets, or to support local workloads in remote or offline locations.
Snowball Edge connects to your existing applications and infrastructure using standard storage interfaces, streamlining the data transfer process and minimizing setup and integration. Snowball Edge can cluster together to form a local storage tier and process your data on-premises, helping ensure your application continues to run even when they are not able to access the cloud.
3.) Snowmobile
AWS Snowmobile is an Exabyte-scale data transfer service used to move extremely large amounts of data to AWS. You can transfer up to 100PB per Snowmobile, a 45 foot long ruggedized shipping container, pulled by a semi-trailer truck. Snowmobile make it easy to move massive volumes of data to the cloud, including video libraries, image repositories, or even a complete data center migration. Transferring data with Snowmobile is secure, fast and cost effective.
Snowball can
----Import to S3
----Export from S3

S3 Transfer Acceleration
S3 Transfer Acceleration utilizes the CloudFront Edge Network to accelerate your uploads to S3. Instead of uploading directly to your S3 bucket, you can use a distinct URL to upload directly to an edge location which will then transfer that file to S3. You will get a distinct URL to upload to.
http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html

S3 Exam Tips
1.) Object based storage i.e. allows you to upload files. Not suitable for installing OS or DB.
2.) Files can be from 0 Bytes to 5TB
3.) Unlimited storage
4.) Files are stored in Buckets
5.) S3 is a universal namespace, thats is, name must be unique globally.
6.) Read after Write consistency for PUTS of new Objects
7.) Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate)
8.) S3 Storage Classes/ Tiers
* S3 - durable, immediately available, frequently accessed
* S3-IA - durable, immediately available, infrequently accessed
* S3 - Reduced Redundancy Storage - data that is easily reproducible such as thumb nails etc.
* Glacier - Archived data, where you can wait 3 - 5 hours before accessing
9.) Fundaments of S3
Key(name)
Value(data)
Version ID
Metadata
Access Control Lists
10.) Versioning
Stores all versions of an object (including all writes even if you delete an object)
Great backup tool
Ones enabled, Versioning cannot be disabled, only suspended
Integrated with Lifecycle rules
Versioning's MFA Delete capability which uses multi-factor authentication can be used to provide an additional layer of security
Cross Region Replication, requires versioning enabled on the source bucket.
11.) Lifecycle Management
* Can be used in conjunction with versioning
* Can be applied to current version and previous version
* Following actions can be performed
Transition to the Standard - Infrequent Access Storage Class (128 kbps and 30 days after the creation date)
Archive to Glacier Storage Class (30 days after IA, if relevant)
Permanently Delete
12.) CloudFront
* Edge Location - Location where content is cached. This is separate to an AWS Region/AZ.
They are not just READ only, you can write to them too.
* Origin - This is the origin of all the files that the CDN will distribute. This can be S3 Bucket, EC2 Instance, an Elastic Load Balancer or Route53.
* Distribution - This is the name given the CDN which consists of a collection of Edge Locations.
2 types of Distributions
** Web Distribution - Used for web sites
** RTMP - Used for Media Streaming
Objects are cached for the life of the TTL (Time To Live)
You can clear cached objects but you will be charged.
13.) Securing your buckets
By default, all newly created buckets are PRIVATE
Setup access control using
--Bucket Policies
--ACL
S3 buckets can be configured to create access logs which log all requests made to the S3 bucket. This can be done to another bucket.
14.) Encryption
1.) In Transit
SSL/TLS
2.) At Rest
2.1) Server Side Encryption
2.1.1) S3 Managed Keys - SSE-S3
2.1.2) AWS Key Management Service, Managed Keys - SSE-KMS
2.1.3) Server Side Encryption With Customer Provided Keys - SSE-C
2.2) Client Side Encryption
15.) Storage Gateway
1.) File Gateways
For flat files, stored directly on S3
2.) Volume Gateway
2.1) Stored Volumes
Entire Dataset is stored on site and is asynchronously backed up to S3
2.2) Cached Volumes
Entire Dataset is stored on S3 and the most frequently accessed data is cached on site
3.) Gateway Virtual Tape Library (VTL)
Used to backup and uses popular backup applications like NetBackup, Backup Exec, Veam etc
16.) Snowball
Snowball
Snowball Edge
Snowmobile
Understand what Snowball is
Understand what Import Export is
Snowball can
- Import to S3
- Export from S3
17.) S3 Transfer Acceleration
You can speed up the transfer to S3 using S3 transfer acceleration. This costs extra, and has a great impact on people who are in far away location.
18.) S3 Static Websites
You can use S3 to host static websites
Server less
Very cheap, scales automatically
STATIC only, cannot host dynamic websites
19.) Important
Write to S3 - HTTP 200 code for successful write.
You can load files to S3 much faster by enabling multipart upload
S3 FAQ
https://aws.amazon.com/s3/faqs/
